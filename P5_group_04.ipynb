{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import _name_estimators\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "validation = pd.read_csv('validation.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train = train[train.payprice >= train.slotprice]\n",
    "validation = validation[validation.payprice >= validation.slotprice]\n",
    "\n",
    "train['size'] = train['slotwidth'] * train['slotheight']\n",
    "validation['size'] = validation['slotwidth'] * validation['slotheight']\n",
    "test['size'] = test['slotwidth'] * test['slotheight']\n",
    "\n",
    "train['OS'], train['browser'] = zip(*train['useragent'].map(lambda x: x.split('_')))\n",
    "validation['OS'], validation['browser'] = zip(*validation['useragent'].map(lambda x: x.split('_')))\n",
    "test['OS'], test['browser'] = zip(*test['useragent'].map(lambda x: x.split('_')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_data(df, enforce_cols=None):\n",
    "    print(\"Input shape:\\t{}\".format(df.shape))\n",
    "    \n",
    "    df.ix[df.slotprice.between(0, 10), 'slotpricebucket'] = 1\n",
    "    df.ix[df.slotprice.between(11, 50), 'slotpricebucket'] = 2\n",
    "    df.ix[df.slotprice.between(51, 100), 'slotpricebucket'] = 3\n",
    "    df.ix[df.slotprice.between(101, 5000), 'slotpricebucket'] = 4\n",
    "    df['slotpricebucket'] = df['slotpricebucket'].astype(np.uint8)\n",
    "\n",
    "    pred=df.drop(['click','bidid','userid','IP','url','urlid','slotid','useragent','slotprice',\n",
    "                 'bidprice','payprice','domain','slotwidth', 'slotheight'],axis=1)\n",
    "    \n",
    "    # create dummy variables for categoricals\n",
    "    pred=pd.get_dummies(pred,dummy_na=True,columns=['weekday', 'hour', \n",
    "                                                       'OS', 'browser', \n",
    "                                                       'region', 'city', 'adexchange', \n",
    "                                                       'slotvisibility', 'slotformat',\n",
    "                                                       'creative', 'slotpricebucket','advertiser'##'ip_block'\n",
    "                                                    ,'keypage','size'])\n",
    "    pred = pred.join(df.usertag.astype(str).str.strip('[]').str.get_dummies(','))\n",
    "    pred=pred.drop(['usertag'],axis=1)\n",
    "    print(\"After converting categoricals:\\t{}\".format(pred.shape))\n",
    "    \n",
    "\n",
    "    # match test set and training set columns\n",
    "    if enforce_cols is not None:\n",
    "        to_drop = np.setdiff1d(pred.columns, enforce_cols)\n",
    "        to_add = np.setdiff1d(enforce_cols, pred.columns)\n",
    "        print(to_add)\n",
    "        print(to_drop)\n",
    "        pred.drop(to_drop, axis=1, inplace=True)\n",
    "        pred = pred.assign(**{c: 0 for c in to_add})\n",
    "    \n",
    "    pred.fillna(0, inplace=True)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def pre_process_data_test(df, enforce_cols=None):\n",
    "    print(\"Input shape:\\t{}\".format(df.shape))\n",
    "    \n",
    "    df.ix[df.slotprice.between(0, 10), 'slotpricebucket'] = 1\n",
    "    df.ix[df.slotprice.between(11, 50), 'slotpricebucket'] = 2\n",
    "    df.ix[df.slotprice.between(51, 100), 'slotpricebucket'] = 3\n",
    "    df.ix[df.slotprice.between(101, 5000), 'slotpricebucket'] = 4\n",
    "    df['slotpricebucket'] = df['slotpricebucket'].astype(np.uint8)\n",
    "\n",
    "    pred=df.drop(['bidid','userid','IP','url','urlid','slotid','useragent','slotprice',\n",
    "                 'domain','slotwidth', 'slotheight'],axis=1)\n",
    "    \n",
    "       # create dummy variables for categoricals\n",
    "    pred = pd.get_dummies(pred,dummy_na=True,columns=['weekday', 'hour',  # ])\n",
    "                                                       'OS', 'browser', \n",
    "                                                       'region', 'city', 'adexchange', \n",
    "                                                       'slotvisibility', 'slotformat',\n",
    "                                                       'creative', 'slotpricebucket','advertiser'##'ip_block'\n",
    "                                                    ,'keypage','size'])\n",
    "    pred = pred.join(df.usertag.astype(str).str.strip('[]').str.get_dummies(','))\n",
    "    pred = pred.drop(['usertag'],axis=1)\n",
    "    print(\"After converting categoricals:\\t{}\".format(pred.shape))\n",
    "    \n",
    "\n",
    "    # match test set and training set columns\n",
    "    if enforce_cols is not None:\n",
    "        to_drop = np.setdiff1d(pred.columns, enforce_cols)\n",
    "        to_add = np.setdiff1d(enforce_cols, pred.columns)\n",
    "        print(to_add)\n",
    "        print(to_drop)\n",
    "        pred.drop(to_drop, axis=1, inplace=True)\n",
    "        pred = pred.assign(**{c: 0 for c in to_add})\n",
    "    \n",
    "    pred.fillna(0, inplace=True)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dum = pre_process_data(train)\n",
    "valid_dum = pre_process_data(validation,enforce_cols=train_dum.columns)\n",
    "test_dum = pre_process_data_test(test,enforce_cols=train_dum.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def order(df_test, df_train):\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    for key in df_train:\n",
    "        new_df[key] = df_test[key]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train.click\n",
    "y_validation = validation.click\n",
    "\n",
    "X_validation = order(valid_dum,train_dum)\n",
    "X_test = order(test_dum,train_dum)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=3,ratio={1:1786,0:10716})\n",
    "X_train,y_train = rus.fit_sample(train_dum,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRT Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train XGBoost\n",
    "\n",
    "#xgb_model = xgboost.XGBClassifier()\n",
    "#parameters = {'nthread':[4], \n",
    "#              'objective':['binary:logistic'],\n",
    "#              'learning_rate':[0.05],\n",
    "#              'max_depth':[5,6,9], \n",
    "#              'min_child_weight':[1,3],\n",
    "#              'silent':[0],\n",
    "#              'subsample':[0.8],\n",
    "#              'colsample_bytree':[0.8],\n",
    "#              'n_estimators':[50,100,200],\n",
    "#              'missing':[-999],\n",
    "#              'seed':[1337]\n",
    "#             }\n",
    "#model_xgb = GridSearchCV(xgb_model, param_grid=parameters, n_jobs=5,\n",
    "#                       cv=StratifiedKFold(y_train, n_folds=10,shuffle=True),\n",
    "#                       scoring='roc_auc',\n",
    "#                       verbose=2,\n",
    "#                       refit=True)\n",
    "#model_xgb.fit(X_train, y_train)\n",
    "#\n",
    "#best_parameters, score, _ = max(model_xgb.grid_scores_, key=lambda x:x[1])\n",
    "#print('Raw ACU score', score)\n",
    "#\n",
    "#for param_name in sorted(best_parameters.keys()):\n",
    "#    print(\"%s: %r\"%(param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Different models\n",
    "### 1.Logidtic Regression  2.Decision Tree   3.Random Forest   4.XGBoost   5.Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MajorityVoteClassifier(BaseEstimator,\n",
    "                            ClassifierMixin):\n",
    "    def __init__(self, classifiers,\n",
    "                 vote='classlabel', weights=None):\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value for\n",
    "                                  key, value in\n",
    "                                  _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):     \n",
    "        self.lablenc_ = LabelEncoder()\n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_ = self.lablenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X,\n",
    "                              self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X),\n",
    "                                 axis=1)\n",
    "        else: # 'classlabel' vote\n",
    "             # Collect results from clf.predict calls\n",
    "            predictions = np.asarray([clf.predict(X)\n",
    "                                      for clf in\n",
    "                                      self.classifiers_]).T\n",
    "            maj_vote = np.apply_along_axis(\n",
    "                           lambda x:\n",
    "                           np.argmax(np.bincount(x,\n",
    "                                        weights=self.weights)),\n",
    "                           axis=1,\n",
    "                           arr=predictions)\n",
    "\n",
    "        maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "                                     \n",
    "    def predict_proba(self, X):\n",
    "        probas = np.asarray([clf.predict_proba(X)\n",
    "                             for clf in self.classifiers_])\n",
    "        avg_proba = np.average(probas,\n",
    "                               axis=0, weights=self.weights)\n",
    "        return avg_proba\n",
    "            \n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Get classifier parameter names for GridSearch\"\"\"\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier,\n",
    "                         self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in\\\n",
    "                    six.iteritems(self.named_classifiers):\n",
    "                for key, value in six.iteritems(\n",
    "                        step.get_params(deep=True)):\n",
    "                    out['%s__%s' % (name, key)] = value\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(penalty = 'l1', max_iter = 100, C = 0.1,\n",
    "                          solver = 'saga',class_weight = 'unbalanced')\n",
    "clf2 = DecisionTreeClassifier(criterion = 'entropy',random_state = 0)\n",
    "clf3 = RandomForestClassifier(n_estimators = 50, random_state = 0)\n",
    "clf4 = xgboost.XGBClassifier(max_depth = 6, n_estimators = 100, learning_rate = 0.05, \n",
    "                             silent = 0,subsample = 0.8, min_child_weight = 3, \n",
    "                             objective = 'binary:logistic',colsample_bytree = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_validation = X_validation.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf1 = MajorityVoteClassifier(classifiers = [clf1,clf3,clf4])\n",
    "mv_clf2 = MajorityVoteClassifier(classifiers = [clf1,clf2,clf3])\n",
    "mv_clf3 = MajorityVoteClassifier(classifiers = [clf3,clf4])\n",
    "mv_clf4 = MajorityVoteClassifier(classifiers = [clf4])\n",
    "clf_labels = ['Ensemble1','Ensemble2','Ensemble3','XGBoost']\n",
    "\n",
    "all_clf = [mv_clf1,mv_clf2,mv_clf3,mv_clf4]\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator = clf,\n",
    "                             X = X_train,\n",
    "                             y = y_train,\n",
    "                             cv = 10,\n",
    "                             scoring = 'roc_auc')\n",
    "    print(\"ROC AUC: %0.4f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating and tuning the ensemble classifier\n",
    "colors = ['blue','green','orange','red']\n",
    "linestyles = [':','--', '-.','-']\n",
    "for clf, label, clr, ls \\\n",
    "        in zip(all_clf, clf_labels, colors, linestyles):\n",
    "     # assuming the label of the positive class is 1\n",
    "    y_pred = clf.fit(X_train,\n",
    "                     y_train).predict_proba(X_validation)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_true = y_validation,\n",
    "                                     y_score = y_pred)\n",
    "    roc_auc = auc(x=fpr, y=tpr)\n",
    "    plt.plot(fpr, tpr,color = clr,linestyle = ls,\n",
    "             label = '%s (auc = %0.4f)' % (label, roc_auc))\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],\n",
    "         linestyle = '--',\n",
    "         color = 'gray',\n",
    "         linewidth = 2)\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Ensemble Model Performance on Validation Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CTR = xgboost.XGBClassifier(max_depth = 6, n_estimators=100, learning_rate=0.05, \n",
    "                                  silent = 0, subsample = 0.8, min_child_weight=3, \n",
    "                                  objective='binary:logistic',colsample_bytree=0.8)\n",
    "model_CTR.fit(X_train, y_train)\n",
    "mv_clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_valid_pre = model_CTR.predict_proba(X_validation)\n",
    "\n",
    "X_test = X_test.as_matrix()\n",
    "y_test_pre = model_CTR.predict_proba(X_test)\n",
    "\n",
    "w=10716/train.shape[0]\n",
    "avgCTR=sum(train.click)/train.shape[0]\n",
    "\n",
    "test_score = y_test_pre[:,1]/(y_test_pre[:,1]+(1-y_test_pre[:,1])/w)\n",
    "valid_score = y_valid_pre[:,1]/(y_valid_pre[:,1]+(1-y_valid_pre[:,1])/w)\n",
    "\n",
    "validation = validation.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidding Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Linear Bidding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_linear = pd.DataFrame(columns=['bid_base','Imps','spend','clicks'])\n",
    "\n",
    "max_num = 0\n",
    "max_bid = 0\n",
    "spend = 0\n",
    "iteration = 0\n",
    "\n",
    "for bid_base in np.arange(3,300, 3):\n",
    "    num_click = 0\n",
    "    flag = True\n",
    "    Imps = 0\n",
    "    spend = 0\n",
    "    iteration += 1\n",
    "    for i in range(validation.shape[0]):\n",
    "        bid = bid_base*(valid_score[i]/avgCTR)\n",
    "        if bid >= validation.payprice[i] and flag:\n",
    "            spend = spend + validation.payprice[i]\n",
    "            if spend > 6250000:\n",
    "                spend = spend - validation.payprice[i]\n",
    "                flag = False\n",
    "                break\n",
    "            num_click = num_click + validation.click[i]\n",
    "            Imps = Imps + 1\n",
    "    eval_linear.loc[iteration,'bid_base'] = bid_base\n",
    "    eval_linear.loc[iteration,'clicks'] = num_click\n",
    "    eval_linear.loc[iteration,'spend'] = spend/1000\n",
    "    eval_linear.loc[iteration,'Imps'] = Imps\n",
    "\n",
    "    if num_click > max_num:\n",
    "        max_num = num_click\n",
    "        max_bid = bid_base\n",
    "        \n",
    "eval_linear['CTR'] = eval_linear['clicks']/eval_linear['Imps']\n",
    "eval_linear['eCPC'] = eval_linear['spend']/eval_linear['clicks']\n",
    "eval_linear['CPM'] = eval_linear['spend']*1000/eval_linear['Imps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_linear.iloc[np.where(eval_linear.clicks == eval_linear.clicks.max())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_line = eval_linear[['bid_base','clicks']].astype(float)\n",
    "second_line = eval_linear[['bid_base','CTR']].astype(float)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(first_line.bid_base,first_line.clicks, color='b')\n",
    "ax1.set_xlabel('Bid')\n",
    "ax1.set_ylabel('Clicks', color='b')\n",
    "ax1.set_ylim([55,170])\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(second_line.bid_base, second_line.CTR, color='g')\n",
    "ax2.set_ylabel('CTR', color='g')\n",
    "plt.title(\"XGBoost CTR Pred. +  Linear Bidding\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Quadratic Bidding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function\n",
    "#bid = base_bid * (pCTR / avgCTR)^2\n",
    "eval_nonlinear = pd.DataFrame(columns=['bid_base','Imps','spend','clicks'])\n",
    "\n",
    "max_num = 0\n",
    "max_bid = 0\n",
    "spend = 0\n",
    "iteration = 0\n",
    "\n",
    "for bid_base in np.arange(3,300, 3):\n",
    "    num_click = 0\n",
    "    flag = True\n",
    "    Imps = 0\n",
    "    spend = 0\n",
    "    iteration += 1\n",
    "    for i in range(validation.shape[0]):\n",
    "        bid = bid_base*(valid_score[i]/avgCTR)**2\n",
    "        if bid >= validation.payprice[i] and flag:\n",
    "            spend = spend + validation.payprice[i]\n",
    "            if spend > 6250000:\n",
    "                spend = spend - validation.payprice[i]\n",
    "                flag = False\n",
    "                break\n",
    "            num_click = num_click + validation.click[i]\n",
    "            Imps = Imps + 1\n",
    "    eval_nonlinear.loc[iteration,'bid_base'] = bid_base\n",
    "    eval_nonlinear.loc[iteration,'clicks'] = num_click\n",
    "    eval_nonlinear.loc[iteration,'spend'] = spend/1000\n",
    "    eval_nonlinear.loc[iteration,'Imps'] = Imps\n",
    "    #print(num_click)\n",
    "    if num_click > max_num:\n",
    "        #print('increase')\n",
    "        max_num = num_click\n",
    "        max_bid = bid_base\n",
    "        \n",
    "eval_nonlinear['CTR'] = eval_nonlinear['clicks']/eval_nonlinear['Imps']\n",
    "eval_nonlinear['eCPC'] = eval_nonlinear['spend']/eval_nonlinear['clicks']\n",
    "eval_nonlinear['CPM'] = eval_nonlinear['spend']*1000/eval_nonlinear['Imps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_nonlinear.iloc[np.where(eval_nonlinear.clicks == eval_nonlinear.clicks.max())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_line = eval_nonlinear[['bid_base','clicks']].astype(float)\n",
    "second_line = eval_nonlinear[['bid_base','CTR']].astype(float)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(first_line.bid_base,first_line.clicks, color='b')\n",
    "ax1.set_xlabel('Bid')\n",
    "ax1.set_ylabel('Clicks', color='b')\n",
    "ax1.set_ylim([55,170])\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(second_line.bid_base, second_line.CTR, color='g')\n",
    "ax2.set_ylabel('CTR', color='g')\n",
    "ax2.set_ylim([0,0.015])\n",
    "plt.title(\"XGBoost CTR Pred. + Quadratic Bidding\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.ORBT1  Bidding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funtion\n",
    "# bid = sqrt(c/lambda pctr + c^2) - c\n",
    "eval_ORBT = pd.DataFrame(columns=['best_c','best_lambda','Imps','spend','clicks'])\n",
    "\n",
    "iteration = 0\n",
    "max_num = 0\n",
    "max_bid = 0\n",
    "spend = 0\n",
    "best_lambda = 0\n",
    "best_c = 0\n",
    "lambda_range = [1e-8,5e-8,1e-7,5e-7,1e-6,5e-6,1e-5,5e-5,1e-4,5e-4]\n",
    "\n",
    "for c in np.arange(4,25,2):\n",
    "    for m in lambda_range:\n",
    "        num_click = 0\n",
    "        flag = True\n",
    "        Imps = 0\n",
    "        spend = 0\n",
    "        iteration += 1\n",
    "        size = validation.shape[0]\n",
    "\n",
    "        for i in range(validation.shape[0]):\n",
    "            bid = np.sqrt(c / m * valid_score[i] + c ** 2) - c\n",
    "\n",
    "            if bid >= validation.payprice[i] and flag:\n",
    "                spend = spend + validation.payprice[i]\n",
    "                if spend > 6250000:\n",
    "                    spend = spend - validation.payprice[i]\n",
    "                    flag = False\n",
    "                    break\n",
    "                num_click = num_click + validation.click[i]\n",
    "                Imps = Imps + 1\n",
    "            \n",
    "        eval_ORBT.loc[iteration,'clicks'] = num_click\n",
    "        eval_ORBT.loc[iteration,'spend'] = spend/1000\n",
    "        eval_ORBT.loc[iteration,'Imps'] = Imps\n",
    "\n",
    "\n",
    "        if num_click > max_num:\n",
    "            max_num = num_click\n",
    "            best_lambda = m\n",
    "            best_c = c\n",
    "            \n",
    "        eval_ORBT.loc[iteration,'best_c'] = best_c\n",
    "        eval_ORBT.loc[iteration,'best_lambda'] = best_lambda\n",
    "\n",
    "            \n",
    "eval_ORBT['CTR'] = eval_ORBT['clicks']/eval_ORBT['Imps']\n",
    "eval_ORBT['eCPC'] = eval_ORBT['spend']/eval_ORBT['clicks']\n",
    "eval_ORBT['CPM'] = eval_ORBT['spend']*1000/eval_ORBT['Imps']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ORBT.iloc[np.where(eval_ORBT.clicks == eval_ORBT.clicks.max())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.ORTB2 Bidding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=pd.DataFrame(columns=['lambda','c_value','imps','cost','click'])\n",
    "y_test = clf6.predict_proba(X_test.as_matrix())\n",
    "y_valid = clf6.predict_proba(X_validation.as_matrix())\n",
    "# y_test = mv_clf.predict_proba(X_test.as_matrix())\n",
    "# y_valid = mv_clf.predict_proba(X_validation.as_matrix())\n",
    "w=10716/train.shape[0]\n",
    "#print(w)\n",
    "test_score=y_test[:,1]/(y_test[:,1]+(1-y_test[:,1])/w)\n",
    "score=y_valid[:,1]/(y_valid[:,1]+(1-y_valid[:,1])/w)\n",
    "\n",
    "\n",
    "max_num=0\n",
    "max_bid=0\n",
    "s=0\n",
    "best_lambda=0\n",
    "c_op=0\n",
    "lambda_range=[1e-6]\n",
    "iteration=0#\n",
    "\n",
    "for c in np.arange(10,26 ,2):\n",
    "    for m in lambda_range:\n",
    "        num_click=0\n",
    "        flag=True\n",
    "        imp=0\n",
    "        s=0\n",
    "        size = validation.shape[0]\n",
    "        iteration+=1\n",
    "        for i in range(validation.shape[0]):\n",
    "            onethird=(score[i]+np.sqrt((c**2) * (m**2)+score[i]**2))/(c*m)\n",
    "            bid=(onethird**(1/3)-onethird**(-1/3))*c\n",
    "            if bid>validation.payprice[i] and flag:\n",
    "                #print('yes')\n",
    "                s=s+validation.payprice[i]\n",
    "                if s>6250000:\n",
    "                    s=s-validation.payprice[i]\n",
    "                    flag=False\n",
    "                    break\n",
    "                num_click=num_click+validation.click[i]\n",
    "                imp=imp+1\n",
    "        result.loc[iteration,'c_value']=c\n",
    "        result.loc[iteration,'lambda']=m\n",
    "        result.loc[iteration,'click']=num_click\n",
    "        result.loc[iteration,'cost']=s\n",
    "        result.loc[iteration,'imps']=imp\n",
    "    print(num_click)\n",
    "    if num_click>max_num:\n",
    "        print('increase')\n",
    "        max_num=num_click\n",
    "        max_bid=c\n",
    "        \n",
    "result['CTR']=result['click']/result['imps']\n",
    "result['eCPC']=result['cost']/result['click']/1000\n",
    "result['CPM']=result['cost']/result['imps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Exponential Bidding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "#bid = base_bid * exp(pCTR / avgCTR)\n",
    "eval_exp = pd.DataFrame(columns=['bid_base','Imps','spend','clicks'])\n",
    "\n",
    "max_num = 0\n",
    "max_bid = 0\n",
    "spend = 0\n",
    "iteration = 0\n",
    "\n",
    "for bid_base in np.arange(3,303, 3):\n",
    "    num_click = 0\n",
    "    flag = True\n",
    "    Imps = 0\n",
    "    spend = 0\n",
    "    iteration += 1\n",
    "    for i in range(validation.shape[0]):\n",
    "        bid = bid_base * np.exp(valid_score[i]/avgCTR)\n",
    "        if bid >= validation.payprice[i] and flag:\n",
    "            spend = spend + validation.payprice[i]\n",
    "            if spend > 6250000:\n",
    "                spend = spend - validation.payprice[i]\n",
    "                flag = False\n",
    "                break\n",
    "            num_click = num_click + validation.click[i]\n",
    "            Imps = Imps + 1\n",
    "    eval_exp.loc[iteration,'bid_base'] = bid_base\n",
    "    eval_exp.loc[iteration,'clicks'] = num_click\n",
    "    eval_exp.loc[iteration,'spend'] = spend/1000\n",
    "    eval_exp.loc[iteration,'Imps'] = Imps\n",
    "\n",
    "    if num_click > max_num:\n",
    "        max_num = num_click\n",
    "        max_bid = bid_base\n",
    "        \n",
    "eval_exp['CTR'] = eval_exp['clicks']/eval_exp['Imps']\n",
    "eval_exp['eCPC'] = eval_exp['spend']/eval_exp['clicks']\n",
    "eval_exp['CPM'] = eval_exp['spend']*1000/eval_exp['Imps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_exp.iloc[np.where(eval_exp.clicks == eval_exp.clicks.max())[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
